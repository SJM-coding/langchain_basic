{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "666a33c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ“˜ Hello! ì¹œê·¼í•œ ì˜ì–´ ì„ ìƒë‹˜ ì‹œì‘\n",
      "\n",
      "ğŸ“¤ ì…ë ¥: ì•ˆë…•í•˜ì„¸ìš”\n",
      "\n",
      "ğŸ“¥ ì¶œë ¥:\n",
      "ë²ˆì—­: Hello  \n",
      "ë¬¸ë²• ì„¤ëª…: 'Hello'ëŠ” ê°€ì¥ ê¸°ë³¸ì ì¸ ì¸ì‚¬ë§ì…ë‹ˆë‹¤.  \n",
      "ì‚¬ìš© ìƒí™©:  \n",
      "- Hello: ê³µì‹, ë¹„ê³µì‹ ëª¨ë‘ ì‚¬ìš© ê°€ëŠ¥  \n",
      "- Hi: ì¡°ê¸ˆ ë” ìºì£¼ì–¼í•œ í‘œí˜„  \n",
      "- Hey: ì¹œêµ¬ë‚˜ ì§€ì¸ê³¼ ì‚¬ìš©í•  ë•Œ ì í•©í•œ í‘œí˜„\n"
     ]
    }
   ],
   "source": [
    "print(\"ğŸ“˜ Hello! ì¹œê·¼í•œ ì˜ì–´ ì„ ìƒë‹˜ ì‹œì‘\")\n",
    "\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from langchain_core.prompts import ChatPromptTemplate, FewShotChatMessagePromptTemplate\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "\n",
    "# âœ… í™˜ê²½ë³€ìˆ˜ ë¡œë“œ\n",
    "load_dotenv()\n",
    "\n",
    "# âœ… Groq ê¸°ë°˜ LLM ì„¤ì •\n",
    "llm = ChatOpenAI(\n",
    "    base_url=\"https://api.groq.com/openai/v1\",\n",
    "    model=\"meta-llama/llama-4-scout-17b-16e-instruct\",\n",
    "    temperature=0.7\n",
    ")\n",
    "\n",
    "# âœ… ì˜ˆì‹œ ë°ì´í„° (few-shot ì˜ˆì‹œ)\n",
    "examples = [\n",
    "    {\n",
    "        \"input\": \"ê°ì‚¬í•©ë‹ˆë‹¤\",\n",
    "        \"output\": \"\"\"ë²ˆì—­: Thank you  \n",
    "ë¬¸ë²• ì„¤ëª…: 'Thank you'ëŠ” ëˆ„êµ°ê°€ì—ê²Œ ê°ì‚¬í•  ë•Œ ê°€ì¥ ê¸°ë³¸ì ì¸ í‘œí˜„ì…ë‹ˆë‹¤.  \n",
    "ì‚¬ìš© ìƒí™©:  \n",
    "- Thank you: ëª¨ë“  ìƒí™©ì—ì„œ ë¬´ë‚œí•˜ê²Œ ì‚¬ìš© ê°€ëŠ¥  \n",
    "- Thanks: ì¡°ê¸ˆ ë” ìºì£¼ì–¼í•œ í‘œí˜„\"\"\"\n",
    "    },\n",
    "    {\n",
    "        \"input\": \"ì˜ ììš”\",\n",
    "        \"output\": \"\"\"ë²ˆì—­: Good night  \n",
    "ë¬¸ë²• ì„¤ëª…: 'Good night'ì€ ë°¤ì— í—¤ì–´ì§€ê±°ë‚˜ ì ìë¦¬ì— ë“¤ê¸° ì „ ì¸ì‚¬í•  ë•Œ ì‚¬ìš©í•©ë‹ˆë‹¤.  \n",
    "ì‚¬ìš© ìƒí™©:  \n",
    "- Good night: ê³µì‹, ë¹„ê³µì‹ ëª¨ë‘ ì‚¬ìš© ê°€ëŠ¥  \n",
    "- Nighty night: ì•„ì´ë“¤ì—ê²Œ ì“°ëŠ” ê·€ì—¬ìš´ í‘œí˜„\"\"\"\n",
    "    }\n",
    "]\n",
    "\n",
    "# âœ… ì˜ˆì‹œ í…œí”Œë¦¿\n",
    "example_prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"human\", \"{input}\"),\n",
    "    (\"ai\", \"{output}\")\n",
    "])\n",
    "\n",
    "# âœ… FewShotPromptTemplate êµ¬ì„±\n",
    "few_shot_prompt = FewShotChatMessagePromptTemplate(\n",
    "    example_prompt=example_prompt,\n",
    "    examples=examples\n",
    ")\n",
    "\n",
    "# âœ… ì „ì²´ í”„ë¡¬í”„íŠ¸ êµ¬ì„±\n",
    "final_prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", \"ë‹¹ì‹ ì€ ì¹œê·¼í•˜ê³  ì´í•´í•˜ê¸° ì‰¬ìš´ ì˜ì–´ ì„ ìƒë‹˜ì…ë‹ˆë‹¤. ë²ˆì—­ê³¼ í•¨ê»˜ ê°„ë‹¨í•œ ë¬¸ë²• ì„¤ëª…ê³¼ ì‚¬ìš© ìƒí™© ì˜ˆì‹œë¥¼ ì œê³µí•´ì£¼ì„¸ìš”.\"),\n",
    "    few_shot_prompt,\n",
    "    (\"human\", \"{input}\")\n",
    "])\n",
    "\n",
    "# âœ… íŒŒì„œ ë° ì²´ì¸ ì—°ê²°\n",
    "parser = StrOutputParser()\n",
    "chain = final_prompt | llm | parser\n",
    "\n",
    "# âœ… í…ŒìŠ¤íŠ¸ ì‹¤í–‰\n",
    "test_input = \"ì•ˆë…•í•˜ì„¸ìš”\"\n",
    "\n",
    "try:\n",
    "    print(f\"\\nğŸ“¤ ì…ë ¥: {test_input}\")\n",
    "    result = chain.invoke({\"input\": test_input})\n",
    "    print(\"\\nğŸ“¥ ì¶œë ¥:\\n\" + result)\n",
    "except Exception as e:\n",
    "    print(f\"âŒ ì˜¤ë¥˜ ë°œìƒ: {e}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "langchain-basic--bIj14hM-py3.12",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
