{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "aafa8183",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['ì„œìš¸ì˜ í•œì •ì‹ ê±°ë¦¬', 'ë¶€ì‚°ì˜ ìê°ˆì¹˜ ì‹œì¥', 'ê´‘ì£¼ì˜ ê¶ì „êµ­ë°¥', 'ëŒ€ì „ì˜ ì„±ì‹¬ë‹¹', 'ì œì£¼ë„ì˜ í‘ë¼ì§€ ê±°ë¦¬']\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.output_parsers import CommaSeparatedListOutputParser\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "from langchain_openai import ChatOpenAI\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "llm = ChatOpenAI(\n",
    "    base_url=\"https://api.groq.com/openai/v1\",\n",
    "    model=\"meta-llama/llama-4-scout-17b-16e-instruct\",\n",
    "    temperature=0.7\n",
    ")\n",
    "\n",
    "output_parser = CommaSeparatedListOutputParser()\n",
    "\n",
    "format_instructions = output_parser.get_format_instructions()\n",
    "\n",
    "prompt = PromptTemplate(\n",
    "    template=\"\"\"ë‹¤ìŒ ì£¼ì œì™€ ê´€ë ¨ëœ í•œêµ­ì˜ ìœ ëª…í•œ ì¥ì†Œë‚˜ í™œë™ 5ê°€ì§€ë¥¼ ì•Œë ¤ì£¼ì„¸ìš”.\n",
    "ì£¼ì œ: {topic}\n",
    "\n",
    "{format_instructions}\"\"\",\n",
    "    input_variables=[\"topic\"],\n",
    "    partial_variables={\"format_instructions\": format_instructions},\n",
    ")\n",
    "\n",
    "chain = prompt | llm | output_parser\n",
    "\n",
    "result = chain.invoke({\"topic\": \"ìŒì‹\"})\n",
    "print(result)  # ['ëª…ë™ ì¹¼êµ­ìˆ˜', 'ë¶€ì‚° ë¼ì§€êµ­ë°¥', ...]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "922e1beb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ§¾ ê°ì • ë¶„ë¥˜ í¬ë§·:\n",
      " Select one of the following options: ê¸ì •, ë¶€ì •, ì¤‘ë¦½\n",
      "\n",
      "ğŸ“ ë¦¬ë·°: ì´ ì˜í™” ì •ë§ ì¬ë¯¸ì—†ì—ˆì–´ìš”. ì‹œê°„ ì•„ê¹Œì› ìŠµë‹ˆë‹¤.\n",
      "ğŸ§  ë¶„ì„ ê²°ê³¼: ë¶€ì •\n",
      "\n",
      "ğŸ“ ë¦¬ë·°: ë°°ìš°ë“¤ì˜ ì—°ê¸°ê°€ í›Œë¥­í•˜ê³ , ìŒì•…ë„ ê°ë™ì ì´ì—ˆì–´ìš”!\n",
      "ğŸ§  ë¶„ì„ ê²°ê³¼: ê¸ì •\n",
      "\n",
      "ğŸ“ ë¦¬ë·°: ê·¸ëƒ¥ ë¬´ë‚œí•œ ì˜í™”ì˜€ë„¤ìš”. ë‚˜ì˜ì§€ë„, ì¢‹ì§€ë„ ì•Šì•˜ì–´ìš”.\n",
      "ğŸ§  ë¶„ì„ ê²°ê³¼: ì¤‘ë¦½\n",
      "\n",
      "ğŸ“ ë¦¬ë·°: ì´ê±´ ìµœê³ ì˜ ì˜í™”ì•¼!!!!ğŸ‘\n",
      "ğŸ§  ë¶„ì„ ê²°ê³¼: ê¸ì •\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain.output_parsers import EnumOutputParser, OutputFixingParser\n",
    "from langchain.schema import OutputParserException\n",
    "from enum import Enum\n",
    "from pprint import pprint\n",
    "\n",
    "# âœ… í™˜ê²½ë³€ìˆ˜ ë¡œë“œ\n",
    "load_dotenv()\n",
    "\n",
    "# âœ… Groq LLM ì„¤ì •\n",
    "llm = ChatOpenAI(\n",
    "    base_url=\"https://api.groq.com/openai/v1\",\n",
    "    model=\"meta-llama/llama-4-scout-17b-16e-instruct\",\n",
    "    temperature=0.3\n",
    ")\n",
    "\n",
    "# âœ… ê°ì • í´ë˜ìŠ¤ ì •ì˜\n",
    "class Sentiment(str, Enum):\n",
    "    POSITIVE = \"ê¸ì •\"\n",
    "    NEGATIVE = \"ë¶€ì •\"\n",
    "    NEUTRAL = \"ì¤‘ë¦½\"\n",
    "\n",
    "# âœ… ì¶œë ¥ íŒŒì„œ ì„¤ì •\n",
    "enum_parser = EnumOutputParser(enum=Sentiment)\n",
    "fixing_parser = OutputFixingParser.from_llm(parser=enum_parser, llm=llm)\n",
    "\n",
    "# âœ… í¬ë§· ì§€ì‹œì‚¬í•­\n",
    "format_instructions = enum_parser.get_format_instructions()\n",
    "print(\"ğŸ§¾ ê°ì • ë¶„ë¥˜ í¬ë§·:\\n\", format_instructions)\n",
    "\n",
    "# âœ… í”„ë¡¬í”„íŠ¸ í…œí”Œë¦¿\n",
    "template = \"\"\"\n",
    "ë‹¹ì‹ ì€ í…ìŠ¤íŠ¸ ê°ì • ë¶„ì„ ì „ë¬¸ê°€ì…ë‹ˆë‹¤.\n",
    "ë‹¤ìŒ í…ìŠ¤íŠ¸ì˜ ê°ì •ì„ ë¶„ì„í•˜ê³ , ë°˜ë“œì‹œ ì•„ë˜ ì„¸ ê°€ì§€ ì¤‘ í•˜ë‚˜ì˜ ë‹¨ì–´ë¡œë§Œ ë‹µë³€í•˜ì„¸ìš”.\n",
    "\n",
    "í…ìŠ¤íŠ¸: \"{text}\"\n",
    "\n",
    "{format_instructions}\n",
    "\n",
    "ì¤‘ìš” ê·œì¹™:\n",
    "1. ë°˜ë“œì‹œ \"ê¸ì •\", \"ë¶€ì •\", \"ì¤‘ë¦½\" ì¤‘ í•˜ë‚˜ì˜ ë‹¨ì–´ë§Œ ì¶œë ¥í•˜ì„¸ìš”\n",
    "2. ë‹¤ë¥¸ ì„¤ëª…ì´ë‚˜ ë¶€ê°€ ì„¤ëª…ì„ ì¶”ê°€í•˜ì§€ ë§ˆì„¸ìš”\n",
    "3. ì´ëª¨ì§€ë‚˜ íŠ¹ìˆ˜ë¬¸ìë„ í¬í•¨í•˜ì§€ ë§ˆì„¸ìš”\n",
    "4. ì˜¤ì§ í•˜ë‚˜ì˜ ë‹¨ì–´ë§Œ ì¶œë ¥í•˜ì„¸ìš”\n",
    "\n",
    "ë‹µë³€:\"\"\"\n",
    "\n",
    "# âœ… ì²´ì¸ êµ¬ì„±\n",
    "prompt = ChatPromptTemplate.from_template(template).partial(\n",
    "    format_instructions=format_instructions\n",
    ")\n",
    "\n",
    "chain = prompt | llm | fixing_parser\n",
    "\n",
    "# âœ… í…ŒìŠ¤íŠ¸ ì…ë ¥\n",
    "test_reviews = [\n",
    "    \"ì´ ì˜í™” ì •ë§ ì¬ë¯¸ì—†ì—ˆì–´ìš”. ì‹œê°„ ì•„ê¹Œì› ìŠµë‹ˆë‹¤.\",\n",
    "    \"ë°°ìš°ë“¤ì˜ ì—°ê¸°ê°€ í›Œë¥­í•˜ê³ , ìŒì•…ë„ ê°ë™ì ì´ì—ˆì–´ìš”!\",\n",
    "    \"ê·¸ëƒ¥ ë¬´ë‚œí•œ ì˜í™”ì˜€ë„¤ìš”. ë‚˜ì˜ì§€ë„, ì¢‹ì§€ë„ ì•Šì•˜ì–´ìš”.\",\n",
    "    \"ì´ê±´ ìµœê³ ì˜ ì˜í™”ì•¼!!!!ğŸ‘\",\n",
    "]\n",
    "\n",
    "# âœ… ì‹¤í–‰\n",
    "for review in test_reviews:\n",
    "    print(f\"\\nğŸ“ ë¦¬ë·°: {review}\")\n",
    "    try:\n",
    "        result = chain.invoke({\"text\": review})\n",
    "        print(\"ğŸ§  ë¶„ì„ ê²°ê³¼:\", result.value)\n",
    "    except OutputParserException as e:\n",
    "        print(\"âŒ íŒŒì‹± ì‹¤íŒ¨:\", str(e))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b8d116cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "name='ê¹€ë¯¼ìˆ˜' age=22 major='ì»´í“¨í„°ê³µí•™' hobbies=['ê²Œì„í•˜ê¸°', 'ì˜í™”ë³´ê¸°', 'ì½”ë”©'] goal='í›Œë¥­í•œ ê°œë°œìê°€ ë˜ëŠ” ê²ƒ'\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.output_parsers import PydanticOutputParser\n",
    "from pydantic import BaseModel, Field\n",
    "\n",
    "class StudentInfo(BaseModel):\n",
    "    name: str = Field(description=\"í•™ìƒì˜ ì´ë¦„\")\n",
    "    age: int = Field(description=\"í•™ìƒì˜ ë‚˜ì´\")\n",
    "    major: str = Field(description=\"í•™ìƒì˜ ì „ê³µ\")\n",
    "    hobbies: list[str] = Field(description=\"í•™ìƒì˜ ì·¨ë¯¸\")\n",
    "    goal: str = Field(description=\"í•™ìƒì˜ ëª©í‘œ\")\n",
    "\n",
    "parser = PydanticOutputParser(pydantic_object=StudentInfo)\n",
    "\n",
    "format_instructions = parser.get_format_instructions()\n",
    "\n",
    "prompt = PromptTemplate(\n",
    "    template=\"\"\"\n",
    "ì•„ë˜ ìê¸°ì†Œê°œë¥¼ ì½ê³ , ì´ë¦„, ë‚˜ì´, ì „ê³µ, ì·¨ë¯¸ ë¦¬ìŠ¤íŠ¸, ëª©í‘œë¥¼ JSON í˜•ì‹ìœ¼ë¡œ ì¶”ì¶œí•´ ì£¼ì„¸ìš”.\n",
    "\n",
    "ìê¸°ì†Œê°œ:\n",
    "{intro}\n",
    "\n",
    "{format_instructions}\n",
    "\"\"\",\n",
    "    input_variables=[\"intro\"],\n",
    "    partial_variables={\"format_instructions\": format_instructions}\n",
    ")\n",
    "\n",
    "chain = prompt | llm | parser\n",
    "\n",
    "intro_text = \"ì•ˆë…•í•˜ì„¸ìš”! ì €ëŠ” ê¹€ë¯¼ìˆ˜ì´ê³  22ì‚´ì…ë‹ˆë‹¤. ì»´í“¨í„°ê³µí•™ì„ ì „ê³µí•˜ê³  ìˆì–´ìš”. ì·¨ë¯¸ë¡œëŠ” ê²Œì„í•˜ê¸°, ì˜í™”ë³´ê¸°, ì½”ë”©ì„ ì¢‹ì•„í•©ë‹ˆë‹¤. ì•ìœ¼ë¡œ í›Œë¥­í•œ ê°œë°œìê°€ ë˜ëŠ” ê²ƒì´ ëª©í‘œì…ë‹ˆë‹¤.\"\n",
    "\n",
    "result = chain.invoke({\"intro\": intro_text})\n",
    "print(result)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "dab9a6d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'destination': 'ë¶€ì‚°', 'duration': '2ë°• 3ì¼', 'budget': '30ë§Œì›', 'rating': '4', 'activities': ['í•´ìš´ëŒ€ ë°”ë‹¤ êµ¬ê²½', 'ìê°ˆì¹˜ì‹œì¥ì—ì„œ íšŒ ë¨¹ê¸°', 'ê°ì²œë¬¸í™”ë§ˆì„ êµ¬ê²½']}\n"
     ]
    }
   ],
   "source": [
    "from langchain.output_parsers import StructuredOutputParser, ResponseSchema\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "from langchain_openai import ChatOpenAI\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# âœ… í™˜ê²½ë³€ìˆ˜ ë¡œë“œ\n",
    "load_dotenv()\n",
    "\n",
    "# âœ… Groq LLM ì„¤ì •\n",
    "llm = ChatOpenAI(\n",
    "    base_url=\"https://api.groq.com/openai/v1\",\n",
    "    model=\"meta-llama/llama-4-scout-17b-16e-instruct\",\n",
    "    temperature=0.5\n",
    ")\n",
    "\n",
    "# âœ… ìŠ¤í‚¤ë§ˆ ì •ì˜\n",
    "schemas = [\n",
    "    ResponseSchema(name=\"destination\", description=\"ì—¬í–‰í•œ ì¥ì†Œ\"),\n",
    "    ResponseSchema(name=\"duration\", description=\"ì—¬í–‰ ê¸°ê°„\"),\n",
    "    ResponseSchema(name=\"budget\", description=\"ì—¬í–‰ ì˜ˆì‚°\"),\n",
    "    ResponseSchema(name=\"rating\", description=\"ë§Œì¡±ë„ ì ìˆ˜ (1~5ì )\"),\n",
    "    ResponseSchema(name=\"activities\", description=\"ì—¬í–‰ì—ì„œ í•œ í™œë™ ë¦¬ìŠ¤íŠ¸\")\n",
    "]\n",
    "\n",
    "parser = StructuredOutputParser(response_schemas=schemas)\n",
    "format_instructions = parser.get_format_instructions()\n",
    "\n",
    "# âœ… í”„ë¡¬í”„íŠ¸\n",
    "prompt = PromptTemplate(\n",
    "    template=\"\"\"ì•„ë˜ ì—¬í–‰ ì´ì•¼ê¸°ë¥¼ ì½ê³ , ì—¬í–‰ì§€, ê¸°ê°„, ì˜ˆì‚°, ë§Œì¡±ë„, í™œë™ ë¦¬ìŠ¤íŠ¸ë¥¼ êµ¬ì¡°í™”ëœ JSON í˜•ì‹ìœ¼ë¡œ ì¶œë ¥í•˜ì„¸ìš”.\n",
    "\n",
    "ì—¬í–‰ í›„ê¸°:\n",
    "{story}\n",
    "\n",
    "{format_instructions}\n",
    "\"\"\",\n",
    "    input_variables=[\"story\"],\n",
    "    partial_variables={\"format_instructions\": format_instructions}\n",
    ")\n",
    "\n",
    "# âœ… ì²´ì¸ ì—°ê²°\n",
    "chain = prompt | llm | parser\n",
    "\n",
    "# âœ… í…ŒìŠ¤íŠ¸ ì…ë ¥\n",
    "story = \"ì§€ë‚œ ì£¼ì— ë¶€ì‚°ìœ¼ë¡œ 2ë°• 3ì¼ ì—¬í–‰ì„ ë‹¤ë…€ì™”ì–´ìš”. ì´ 30ë§Œì› ì •ë„ ì¼ëŠ”ë° í•´ìš´ëŒ€ì—ì„œ ë°”ë‹¤êµ¬ê²½í•˜ê³ , ìê°ˆì¹˜ì‹œì¥ì—ì„œ íšŒ ë¨¹ê³ , ê°ì²œë¬¸í™”ë§ˆì„ë„ êµ¬ê²½í–ˆì–´ìš”. ì •ë§ ë§Œì¡±ìŠ¤ëŸ¬ìš´ ì—¬í–‰ì´ì—ˆìŠµë‹ˆë‹¤. 5ì  ë§Œì ì— 4ì  ì •ë„ ì¤„ ìˆ˜ ìˆì„ ê²ƒ ê°™ì•„ìš”.\"\n",
    "\n",
    "result = chain.invoke({\"story\": story})\n",
    "print(result)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "langchain-basic--bIj14hM-py3.12",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
